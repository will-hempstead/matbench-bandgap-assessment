{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897d4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03dbe552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experimental data into pandas dataframe\n",
    "\n",
    "df_exp = pd.read_csv(\"team-a.csv\")\n",
    "df_exp = df_exp.drop(['formula'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40c44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split experimental data\n",
    "\n",
    "X_exp = df_exp[['MagpieData maximum MendeleevNumber', 'MagpieData mean AtomicWeight',\n",
    "       'MagpieData minimum MeltingT', 'MagpieData maximum MeltingT',\n",
    "       'MagpieData mean MeltingT', 'MagpieData minimum Column',\n",
    "       'MagpieData range Column', 'MagpieData avg_dev Column',\n",
    "       'MagpieData mode Column', 'MagpieData range Row', 'MagpieData mean Row',\n",
    "       'MagpieData range Electronegativity',\n",
    "       'MagpieData avg_dev Electronegativity',\n",
    "       'MagpieData mode Electronegativity', 'MagpieData mean NpValence',\n",
    "       'MagpieData maximum NdValence', 'MagpieData range NdValence',\n",
    "       'MagpieData mean NdValence', 'MagpieData maximum NfValence',\n",
    "       'MagpieData mean NfValence', 'MagpieData mean NValence',\n",
    "       'MagpieData mode NValence', 'MagpieData maximum NpUnfilled',\n",
    "       'MagpieData range NpUnfilled', 'MagpieData mean NpUnfilled',\n",
    "       'MagpieData range NUnfilled', 'MagpieData mean NUnfilled',\n",
    "       'MagpieData mode NUnfilled', 'MagpieData minimum GSvolume_pa',\n",
    "       'MagpieData mode GSvolume_pa', 'MagpieData maximum GSbandgap',\n",
    "       'MagpieData range GSbandgap', 'MagpieData mode GSbandgap',\n",
    "       'MagpieData mean GSmagmom', 'MagpieData mode SpaceGroupNumber']].values\n",
    "\n",
    "\n",
    "y_exp = df_exp['gap expt'].values\n",
    "y_exp = y_exp.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3b4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_exp)\n",
    "y_scaled = scaler_y.fit_transform(y_exp)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_scaled,y_scaled,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d246e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=34, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d35590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some model parameters\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, 128),   \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)  \n",
    ")\n",
    "\n",
    "# and optimiser\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d54aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train loss: 0.8221, Val loss: 0.7594\n",
      "Epoch [2/100], Train loss: 0.6317, Val loss: 0.6152\n",
      "Epoch [3/100], Train loss: 0.5515, Val loss: 0.5772\n",
      "Epoch [4/100], Train loss: 0.5005, Val loss: 0.5182\n",
      "Epoch [5/100], Train loss: 0.4670, Val loss: 0.5414\n",
      "Epoch [6/100], Train loss: 0.4304, Val loss: 0.5086\n",
      "Epoch [7/100], Train loss: 0.4064, Val loss: 0.5155\n",
      "Epoch [8/100], Train loss: 0.3963, Val loss: 0.4824\n",
      "Epoch [9/100], Train loss: 0.3849, Val loss: 0.4681\n",
      "Epoch [10/100], Train loss: 0.3539, Val loss: 0.4462\n",
      "Epoch [11/100], Train loss: 0.3417, Val loss: 0.4588\n",
      "Epoch [12/100], Train loss: 0.3348, Val loss: 0.4644\n",
      "Epoch [13/100], Train loss: 0.3237, Val loss: 0.4489\n",
      "Epoch [14/100], Train loss: 0.3030, Val loss: 0.4703\n",
      "Epoch [15/100], Train loss: 0.3098, Val loss: 0.4478\n",
      "Epoch [16/100], Train loss: 0.3012, Val loss: 0.4291\n",
      "Epoch [17/100], Train loss: 0.2825, Val loss: 0.4574\n",
      "Epoch [18/100], Train loss: 0.2813, Val loss: 0.4362\n",
      "Epoch [19/100], Train loss: 0.2720, Val loss: 0.4627\n",
      "Epoch [20/100], Train loss: 0.2698, Val loss: 0.4467\n",
      "Epoch [21/100], Train loss: 0.2453, Val loss: 0.4308\n",
      "Epoch [22/100], Train loss: 0.2524, Val loss: 0.4180\n",
      "Epoch [23/100], Train loss: 0.2338, Val loss: 0.4414\n",
      "Epoch [24/100], Train loss: 0.2338, Val loss: 0.3929\n",
      "Epoch [25/100], Train loss: 0.2252, Val loss: 0.4214\n",
      "Epoch [26/100], Train loss: 0.2303, Val loss: 0.4081\n",
      "Epoch [27/100], Train loss: 0.2206, Val loss: 0.3932\n",
      "Epoch [28/100], Train loss: 0.2107, Val loss: 0.4082\n",
      "Epoch [29/100], Train loss: 0.2092, Val loss: 0.5320\n",
      "Epoch [30/100], Train loss: 0.2000, Val loss: 0.4041\n",
      "Epoch [31/100], Train loss: 0.1900, Val loss: 0.3936\n",
      "Epoch [32/100], Train loss: 0.1893, Val loss: 0.3854\n",
      "Epoch [33/100], Train loss: 0.1838, Val loss: 0.4187\n",
      "Epoch [34/100], Train loss: 0.1831, Val loss: 0.4151\n",
      "Epoch [35/100], Train loss: 0.1834, Val loss: 0.4680\n",
      "Epoch [36/100], Train loss: 0.1733, Val loss: 0.3988\n",
      "Epoch [37/100], Train loss: 0.1697, Val loss: 0.4037\n",
      "Epoch [38/100], Train loss: 0.1865, Val loss: 0.3945\n",
      "Epoch [39/100], Train loss: 0.1687, Val loss: 0.4173\n",
      "Epoch [40/100], Train loss: 0.1587, Val loss: 0.3912\n",
      "Epoch [41/100], Train loss: 0.1654, Val loss: 0.3745\n",
      "Epoch [42/100], Train loss: 0.1540, Val loss: 0.3889\n",
      "Epoch [43/100], Train loss: 0.1532, Val loss: 0.4242\n",
      "Epoch [44/100], Train loss: 0.1623, Val loss: 0.3772\n",
      "Epoch [45/100], Train loss: 0.1453, Val loss: 0.4049\n",
      "Epoch [46/100], Train loss: 0.1497, Val loss: 0.3661\n",
      "Epoch [47/100], Train loss: 0.1536, Val loss: 0.4244\n",
      "Epoch [48/100], Train loss: 0.1394, Val loss: 0.3911\n",
      "Epoch [49/100], Train loss: 0.1310, Val loss: 0.4020\n",
      "Epoch [50/100], Train loss: 0.1359, Val loss: 0.3955\n",
      "Epoch [51/100], Train loss: 0.1290, Val loss: 0.4282\n",
      "Epoch [52/100], Train loss: 0.1480, Val loss: 0.4107\n",
      "Epoch [53/100], Train loss: 0.1399, Val loss: 0.3834\n",
      "Epoch [54/100], Train loss: 0.1242, Val loss: 0.3562\n",
      "Epoch [55/100], Train loss: 0.1275, Val loss: 0.4373\n",
      "Epoch [56/100], Train loss: 0.1276, Val loss: 0.3759\n",
      "Epoch [57/100], Train loss: 0.1232, Val loss: 0.3804\n",
      "Epoch [58/100], Train loss: 0.1153, Val loss: 0.3711\n",
      "Epoch [59/100], Train loss: 0.1156, Val loss: 0.3936\n",
      "Epoch [60/100], Train loss: 0.1115, Val loss: 0.3789\n",
      "Epoch [61/100], Train loss: 0.1206, Val loss: 0.3954\n",
      "Epoch [62/100], Train loss: 0.1090, Val loss: 0.3807\n",
      "Epoch [63/100], Train loss: 0.1107, Val loss: 0.3869\n",
      "Epoch [64/100], Train loss: 0.1142, Val loss: 0.3637\n",
      "Epoch [65/100], Train loss: 0.1284, Val loss: 0.3891\n",
      "Epoch [66/100], Train loss: 0.1092, Val loss: 0.3754\n",
      "Epoch [67/100], Train loss: 0.1041, Val loss: 0.3687\n",
      "Epoch [68/100], Train loss: 0.1088, Val loss: 0.3987\n",
      "Epoch [69/100], Train loss: 0.1011, Val loss: 0.3793\n",
      "Epoch [70/100], Train loss: 0.1088, Val loss: 0.4156\n",
      "Epoch [71/100], Train loss: 0.1187, Val loss: 0.3971\n",
      "Epoch [72/100], Train loss: 0.1073, Val loss: 0.4144\n",
      "Epoch [73/100], Train loss: 0.1039, Val loss: 0.3713\n",
      "Epoch [74/100], Train loss: 0.0949, Val loss: 0.3622\n",
      "Epoch [75/100], Train loss: 0.0882, Val loss: 0.3716\n",
      "Epoch [76/100], Train loss: 0.0958, Val loss: 0.4208\n",
      "Epoch [77/100], Train loss: 0.0906, Val loss: 0.3628\n",
      "Epoch [78/100], Train loss: 0.0891, Val loss: 0.3760\n",
      "Epoch [79/100], Train loss: 0.0871, Val loss: 0.4295\n",
      "Epoch [80/100], Train loss: 0.0947, Val loss: 0.5135\n",
      "Epoch [81/100], Train loss: 0.0931, Val loss: 0.3780\n",
      "Epoch [82/100], Train loss: 0.0841, Val loss: 0.3850\n",
      "Epoch [83/100], Train loss: 0.0882, Val loss: 0.3750\n",
      "Epoch [84/100], Train loss: 0.0892, Val loss: 0.3623\n",
      "Epoch [85/100], Train loss: 0.0921, Val loss: 0.3584\n",
      "Epoch [86/100], Train loss: 0.0936, Val loss: 0.3990\n",
      "Epoch [87/100], Train loss: 0.0928, Val loss: 0.3614\n",
      "Epoch [88/100], Train loss: 0.0760, Val loss: 0.3785\n",
      "Epoch [89/100], Train loss: 0.0740, Val loss: 0.3639\n",
      "Epoch [90/100], Train loss: 0.0753, Val loss: 0.3591\n",
      "Epoch [91/100], Train loss: 0.0790, Val loss: 0.3725\n",
      "Epoch [92/100], Train loss: 0.0867, Val loss: 0.3681\n",
      "Epoch [93/100], Train loss: 0.0807, Val loss: 0.3724\n",
      "Epoch [94/100], Train loss: 0.0689, Val loss: 0.3709\n",
      "Epoch [95/100], Train loss: 0.0764, Val loss: 0.3654\n",
      "Epoch [96/100], Train loss: 0.0759, Val loss: 0.3506\n",
      "Epoch [97/100], Train loss: 0.0778, Val loss: 0.3682\n",
      "Epoch [98/100], Train loss: 0.0750, Val loss: 0.3597\n",
      "Epoch [99/100], Train loss: 0.0775, Val loss: 0.3913\n",
      "Epoch [100/100], Train loss: 0.0683, Val loss: 0.4041\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "# Number of complete passes through the dataset\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# keep track of the loss for each epoch\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Start the training loop\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Iterate over the validation data and compute the loss\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # turn off gradients since we are in the evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            val_predictions = model(X_val)\n",
    "            loss = criterion(val_predictions, y_val)\n",
    "\n",
    "            # Add the loss for this batch to the validation loss\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "    val_losses.append(val_loss/len(val_loader))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train loss: {train_losses[-1]:.4f}, Val loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ee6ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 0.4725\n"
     ]
    }
   ],
   "source": [
    "# calculate mae, dont fully understand this code -check\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get all predictions\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader: \n",
    "        predictions = model(X_batch)\n",
    "        all_predictions.append(predictions)\n",
    "        all_targets.append(y_batch)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_predictions = torch.cat(all_predictions)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "# Convert to numpy and unscale (IMPORTANT!)\n",
    "predictions_scaled = all_predictions.numpy()\n",
    "targets_scaled = all_targets.numpy()\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "predictions_original = scaler_y.inverse_transform(predictions_scaled)\n",
    "targets_original = scaler_y.inverse_transform(targets_scaled)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(targets_original, predictions_original)\n",
    "print(f\"Validation MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab55dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
