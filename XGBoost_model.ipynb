{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52559269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a87312e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"team-a.csv\")\n",
    "df = df.drop(['formula'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49c520ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exp = df.drop(['gap expt'],axis=1).values\n",
    "y_exp = df['gap expt'].values\n",
    "y_exp = y_exp.reshape(-1,1)\n",
    "X_train_exp,X_test_exp,y_train_exp,y_test_exp = train_test_split(X_exp,y_exp,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.46 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost without tuning - no real improvement on random forest\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "scores = cross_val_score(xgb_model, X_train_exp, y_train_exp, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "mae_scores = -scores\n",
    "mae_scores\n",
    "print(f\"Mean absolute error: {mae_scores.mean():.2f} (+/- {mae_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f42dc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "Best mean absolute error: -0.69\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters\n",
    "# this approach uses randomsearch which randomly goes through combinations of parameters\n",
    "# for different datasets different tuning methods may be better\n",
    "# BO - best for slow training (large dataset) and want to minimise the number of times you train\n",
    "# grid search - best for small hyperparameter space\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_model, param_dist, n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_exp, y_train_exp)\n",
    "\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best mean absolute error: {-random_search.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1899e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.43 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost with tuned hyperparameters - an improvement in MAE\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=200,subsample=0.8,max_depth=7,learning_rate=0.1,random_state=42)\n",
    "\n",
    "scores = cross_val_score(xgb_model, X_train_exp, y_train_exp, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "mae_scores = -scores\n",
    "mae_scores\n",
    "print(f\"Mean absolute error: {mae_scores.mean():.2f} (+/- {mae_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eeaf1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance for xgboost. same MAE if you exlude 74% least important features \n",
    "\n",
    "xgb_model.fit(X_train_exp, y_train_exp)\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "threshold = np.percentile(importances, 74)\n",
    "important_features = importances > threshold\n",
    "X_train_reduced = X_train_exp[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7302ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.43 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# retraining with important features only\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=200,subsample=0.8,max_depth=7,learning_rate=0.1,random_state=42)\n",
    "\n",
    "scores = cross_val_score(xgb_model, X_train_reduced, y_train_exp, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "mae_scores = -scores\n",
    "mae_scores\n",
    "print(f\"Mean absolute error: {mae_scores.mean():.2f} (+/- {mae_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90045e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MagpieData maximum MendeleevNumber', 'MagpieData mean AtomicWeight',\n",
      "       'MagpieData minimum MeltingT', 'MagpieData maximum MeltingT',\n",
      "       'MagpieData mean MeltingT', 'MagpieData minimum Column',\n",
      "       'MagpieData range Column', 'MagpieData avg_dev Column',\n",
      "       'MagpieData mode Column', 'MagpieData range Row', 'MagpieData mean Row',\n",
      "       'MagpieData range Electronegativity',\n",
      "       'MagpieData avg_dev Electronegativity',\n",
      "       'MagpieData mode Electronegativity', 'MagpieData mean NpValence',\n",
      "       'MagpieData maximum NdValence', 'MagpieData range NdValence',\n",
      "       'MagpieData mean NdValence', 'MagpieData maximum NfValence',\n",
      "       'MagpieData mean NfValence', 'MagpieData mean NValence',\n",
      "       'MagpieData mode NValence', 'MagpieData maximum NpUnfilled',\n",
      "       'MagpieData range NpUnfilled', 'MagpieData mean NpUnfilled',\n",
      "       'MagpieData range NUnfilled', 'MagpieData mean NUnfilled',\n",
      "       'MagpieData mode NUnfilled', 'MagpieData minimum GSvolume_pa',\n",
      "       'MagpieData mode GSvolume_pa', 'MagpieData maximum GSbandgap',\n",
      "       'MagpieData range GSbandgap', 'MagpieData mode GSbandgap',\n",
      "       'MagpieData mean GSmagmom', 'MagpieData mode SpaceGroupNumber'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# which features are important? 34 features in total \n",
    "# first add extra False into array to make it correct shape\n",
    "\n",
    "important_features = np.insert(important_features,0,False)\n",
    "\n",
    "# and extract important feature names\n",
    "important_feature_names = df.columns[important_features]\n",
    "print(important_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
